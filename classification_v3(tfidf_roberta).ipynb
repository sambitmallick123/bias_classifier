{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"classification_v3(tfidf_roberta).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMheN2IGWwBt1oNcMKv5aY8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fbmfEIWExuGE","executionInfo":{"status":"ok","timestamp":1643477662192,"user_tz":-60,"elapsed":3121,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}},"outputId":"f2cd4c39-9cae-4c3f-c6f3-31851de08a14"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}],"source":["import tensorflow as tf\n","# Getting GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"]},{"cell_type":"code","source":["import torch\n","# If a GPU is available\n","if torch.cuda.is_available():    \n","    #set device to GPU   \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If no GPU is available\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oTzMXyabx4Hm","executionInfo":{"status":"ok","timestamp":1643477666853,"user_tz":-60,"elapsed":4665,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}},"outputId":"e69b94ba-0d5b-4de3-f30d-47052e9578d8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"]}]},{"cell_type":"code","source":["!pip install transformers\n","\n","import re\n","import scipy\n","import pandas         as pd\n","import io\n","import numpy          as np\n","import copy\n","import seaborn        as sns\n","\n","import transformers\n","from transformers                     import  RobertaModel, RobertaTokenizer, AdamW, get_linear_schedule_with_warmup\n","import torch\n","from sklearn.metrics                  import classification_report\n","from sklearn.metrics                  import confusion_matrix\n","from sklearn.feature_extraction.text  import TfidfVectorizer\n","from sklearn.utils                    import class_weight\n","\n","from torch                            import nn, optim\n","from torch.utils                      import data\n","from sklearn.decomposition            import PCA\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JRaYLsljx4FU","executionInfo":{"status":"ok","timestamp":1643477672866,"user_tz":-60,"elapsed":6019,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}},"outputId":"022a172d-1eb2-4beb-9e3d-4c89152a4d19"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.4)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"]}]},{"cell_type":"code","source":["#Seeding for deterministic results\n","RANDOM_SEED = 16\n","np.random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)\n","\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(RANDOM_SEED)\n","    torch.cuda.manual_seed_all(RANDOM_SEED) \n","    torch.backends.cudnn.deterministic = True  \n","    torch.backends.cudnn.benchmark = False\n","\n","CLASS_NAMES = ['0','1']\n","# CLASS_NAMES =['Non-ADU','ADU']\n"],"metadata":{"id":"NF0BsXFLx4Cy","executionInfo":{"status":"ok","timestamp":1643477672867,"user_tz":-60,"elapsed":9,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["MAX_LENGTH = 200                                    \n","BATCH_SIZE = 16\n","EPOCHS = 5\n","HIDDEN_UNITS = 128\n","\n","tokenizer = transformers.RobertaTokenizer.from_pretrained('roberta-large')  #Use roberta-large or roberta-base"],"metadata":{"id":"GUZcXC4Ix4AS","executionInfo":{"status":"ok","timestamp":1643477675295,"user_tz":-60,"elapsed":2437,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3h5EJ4_Mx39y","executionInfo":{"status":"ok","timestamp":1643477676919,"user_tz":-60,"elapsed":1627,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}},"outputId":"ae07653e-2059-4d5e-952a-5a62d4fd6dd8"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["train_df=pd.read_csv(F\"/content/gdrive/My Drive/SAMBIT/master_thesis/data/train.tsv\", sep='\\t', header=None, index_col=False)\n","dev_df=pd.read_csv(F\"/content/gdrive/My Drive/SAMBIT/master_thesis/data/dev.tsv\", sep='\\t', header=None, index_col=False)\n","test_df=pd.read_csv(F\"/content/gdrive/My Drive/SAMBIT/master_thesis/data/test.tsv\", sep='\\t', header=None, index_col=False)\n","\n","large_train_df=pd.read_csv(F\"/content/gdrive/My Drive/SAMBIT/master_thesis/data/noisy_train.tsv\", sep='\\t', header=None, index_col=False)"],"metadata":{"id":"CJXIekBBx37M","executionInfo":{"status":"ok","timestamp":1643477678126,"user_tz":-60,"elapsed":1211,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Preprocess\n","\n","col = {0:\"sentences\", 1:\"label0\", 2:\"label\" }\n","\n","train_df = train_df.rename(columns = col)\n","dev_df = dev_df.rename(columns = col)\n","test_df = test_df.rename(columns = col)\n","large_train_df = large_train_df.rename(columns = col)\n","\n","train_df = train_df.drop(columns=['label0'])\n","dev_df = dev_df.drop(columns=['label0'])\n","test_df = test_df.drop(columns=['label0'])\n","large_train_df = large_train_df.drop(columns=['label0'])"],"metadata":{"id":"iftk3aZwx34u","executionInfo":{"status":"ok","timestamp":1643477678126,"user_tz":-60,"elapsed":4,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#Creates a dataset which will be used to feed to RoBERTa\n","class BiasDataset(data.Dataset):\n","  def __init__(self,sentences, labels, tokenizer, max_len):\n","\n","    # def __init__(self,firstSeq,sentences, labelValue,  tokenizer, max_len):\n","#     def __init__(self, firstSeq, secondSeq, sentences, labelValue,  tokenizer, max_len):\n","        # self.firstSeq    = firstSeq      #First input sequence that will be supplied to RoBERTa\n","        # self.secondSeq   = secondSeq     #Second input sequence that will be supplied to RoBERTa\n","        self.sentences = sentences   #Concatenation of reply+ previous+ src text to get features from 1 training example\n","        # self.Features = Features\n","        self.labels  = labels    #label value for each training example in the dataset\n","        self.tokenizer   = tokenizer     #tokenizer that will be used to tokenize input sequences (Uses BERT-tokenizer here)\n","        self.max_len     = max_len       #Maximum length of the tokens from the input sequence that BERT needs to attend to\n","\n","  def __len__(self):\n","        return len(self.labels)\n","\n","  def __getitem__(self, item):\n","        # firstSeq    = str(self.firstSeq[item])\n","        # secondSeq   = str(self.secondSeq[item])\n","        sentences = str(self.sentences[item])\n","        # Features = str(self.Features[item])\n","\n","    #Encoding the first and the second sequence to a form accepted by RoBERTa\n","    #RoBERTa does not use token_type_ids to distinguish the first sequence from the second sequnece.\n","        encoding = tokenizer.encode_plus(\n","            # firstSeq,\n","            # secondSeq,\n","            sentences,\n","            # Features,\n","            max_length = self.max_len,\n","            add_special_tokens= True,\n","            truncation = True,\n","            pad_to_max_length = True,\n","            # padding=True,\n","            return_attention_mask = True,\n","            return_tensors = 'pt'\n","        )\n","\n","        return {\n","            # 'firstSeq' : firstSeq,\n","            # 'secondSeq' : secondSeq,\n","            'sentences': sentences,\n","            # 'Features' : Features,\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'labels'  : torch.tensor(self.labels[item], dtype=torch.long)\n","        }\n"],"metadata":{"id":"9g1Bj8Uex32V","executionInfo":{"status":"ok","timestamp":1643477678126,"user_tz":-60,"elapsed":3,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#Creates a data loader\n","def createDataLoader(dataframe, tokenizer, max_len, batch_size):\n","    ds = BiasDataset(\n","        # firstSeq    = dataframe.Topic.to_numpy(),\n","        # secondSeq   = dataframe.Topic.to_numpy(),\n","        sentences = dataframe.sentences.to_numpy(),\n","        # Features = dataframe.Features.to_numpy(),\n","        labels  = dataframe.label.to_numpy(),\n","        tokenizer   = tokenizer,\n","        max_len     = max_len\n","    )\n","\n","    return data.DataLoader(\n","        ds,\n","        batch_size  = batch_size,\n","        shuffle     = True,\n","        num_workers = 2\n","    )"],"metadata":{"id":"rOscOPkFx3zu","executionInfo":{"status":"ok","timestamp":1643477678126,"user_tz":-60,"elapsed":3,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#Creating data loader for training data\n","trainDataLoader        = createDataLoader(train_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n","\n","#Creating data loader for development data\n","developmentDataLoader  = createDataLoader(dev_df, tokenizer, MAX_LENGTH, BATCH_SIZE)\n","\n","#Creating data loader for test data\n","testDataLoader         = createDataLoader(test_df, tokenizer, MAX_LENGTH, BATCH_SIZE)"],"metadata":{"id":"VROjON1xx3xO","executionInfo":{"status":"ok","timestamp":1643477678127,"user_tz":-60,"elapsed":4,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# train_df"],"metadata":{"id":"BkR3cCZOx3u8","executionInfo":{"status":"ok","timestamp":1643477203530,"user_tz":-60,"elapsed":5,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["#Instantiating the tf-idf vectorizer object\n","tfidf = TfidfVectorizer(min_df = 10, max_df = 0.5, ngram_range=(1,2))\n","\n","x_train = train_df['sentences'].tolist()\n","y_train = train_df['label'].tolist()\n","\n","x_train_feats = tfidf.fit(x_train)\n","print('x_train_feats: ',x_train_feats)\n","print('length: ',len(x_train_feats.get_feature_names()))\n","\n","x_train_transform = x_train_feats.transform(x_train)\n","tfidf_transform_tensor = torch.tensor(scipy.sparse.csr_matrix.todense(x_train_transform)).float()\n","print('x_train_transform.shape: ',x_train_transform.shape)\n","\n","pca = PCA(n_components=128)\n","p = pca.fit(tfidf_transform_tensor)\n","# print(p.shape)\n","print(p)\n","X = p.transform(tfidf_transform_tensor)\n","# torch.from_numpy(X.values)\n","X = torch.from_numpy(X)\n","# tfidf_transform_tensor_pca = torch.tensor(scipy.sparse.csr_matrix.todense(X)).float()\n","print(X.type())\n","print(X.shape)\n","print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T21MogODx3sy","executionInfo":{"status":"ok","timestamp":1643477684339,"user_tz":-60,"elapsed":4981,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}},"outputId":"b8302dbe-a0d0-4b27-f95a-df785b06fa7a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["x_train_feats:  TfidfVectorizer(max_df=0.5, min_df=10, ngram_range=(1, 2))\n","length:  2402\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"stream","name":"stdout","text":["x_train_transform.shape:  (5028, 2402)\n","PCA(n_components=128)\n","torch.DoubleTensor\n","torch.Size([5028, 128])\n","tensor([[-0.0317, -0.0838, -0.0244,  ..., -0.0452, -0.0785, -0.0181],\n","        [-0.0253, -0.0745, -0.0191,  ..., -0.0204, -0.0470, -0.0255],\n","        [ 0.1365,  0.0091, -0.0550,  ...,  0.0352, -0.0274, -0.0181],\n","        ...,\n","        [ 0.0142,  0.0354,  0.0247,  ..., -0.0164, -0.0534, -0.0472],\n","        [-0.0094, -0.0126,  0.0431,  ...,  0.0109, -0.0463,  0.0152],\n","        [-0.0053, -0.0172,  0.0506,  ..., -0.0160, -0.0282,  0.0070]],\n","       dtype=torch.float64)\n"]}]},{"cell_type":"code","source":["#This class defines the model that was used to pre-train a SNN on TF-IDF features\n","class Tfidf_Nn(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        \n","        # Inputs to hidden layer linear transformation\n","        self.hidden  = nn.Linear(len(tfidf.get_feature_names()), HIDDEN_UNITS)\n","        # Output layer\n","        self.output  =  nn.Linear(HIDDEN_UNITS, 3)\n","        self.dropout = nn.Dropout(0.1)\n","        \n","        # Defining tanh activation and softmax output \n","        self.tanh = nn.Tanh()\n","        self.softmax = nn.Softmax(dim=1)\n","        \n","    def forward(self, x):\n","        # Pass the input tensor through each of our operations\n","        x = self.hidden(x)\n","        #print(x.shape)\n","        y = self.tanh(x)\n","        #print(y.shape)\n","        z = self.dropout(y)\n","        #print(z.shape)\n","        z = self.output(z)\n","        #print(z.shape)\n","        z = self.softmax(z)\n","        \n","        #Returning the ouputs from the hidden layer and the final output layer\n","        return  y, z"],"metadata":{"id":"z35CDHikx3qa","executionInfo":{"status":"ok","timestamp":1643477684339,"user_tz":-60,"elapsed":5,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["snnmodel = Tfidf_Nn()\n","\n","model_save_name = 'bias_classify_roberta_tfidf.pt'\n","path = F\"{model_save_name}\"\n","\n","# snnmodel.load_state_dict(torch.load(path))\n","snnmodel.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L5k_br_hx3oD","executionInfo":{"status":"ok","timestamp":1643477685268,"user_tz":-60,"elapsed":413,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}},"outputId":"e2689760-6982-493d-9dea-37fb4aea12e5"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"execute_result","data":{"text/plain":["Tfidf_Nn(\n","  (hidden): Linear(in_features=2402, out_features=128, bias=True)\n","  (output): Linear(in_features=128, out_features=3, bias=True)\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (tanh): Tanh()\n","  (softmax): Softmax(dim=1)\n",")"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["'''This class defines the model that will be used for \n","training and testing on the dataset.\n","\n","Adapted from huggingFace\n","This RoBERTa model from huggingface outputs the last hidden states\n","and the pooled output by default. Pooled output is the classification \n","token (1st token of the last hidden state) further processed by a Linear\n","layer and a Tanh activation function.\n","\n","The pre-trained RoBERTa model is used as the primary model.\n","This class experiments with RoBERTa and its ensemble with TF-IDF features. \n","roberta-only :            No ensembling. This just fine-tunes the RoBERTa model. \n","                          The pooled output is passed through a linear layer and \n","                          softmax function is finally used for preictions. \n","\n","roberta-tfIdf :           This model conatenates the 1st token of last-hidden layer\n","                          from RoBERTa with TF-IDF features. Various ways of this \n","                          concatenation was experimented (using pooled output instead\n","                          of 1st token of last hidden layer etc)\n","\n","roberta-pcaTfidf :        This model concatenates the pooled output from\n","                          RoBERTa with the PCA transformed vector.\n","\n","roberta-preTrainedTfIdf : This model concatenates the pooled output from\n","                          RoBERTa with the hidden layer output from a pre-trained\n","                          SNN that was trained on TF-IDF features.\n","\n","Used dropout to prevent over-fitting.'''\n","\n","class BiasClassifier(nn.Module):\n","\n","    def __init__(self,  n_classes):\n","        super(BiasClassifier, self).__init__()\n","        self.robertaModel              = RobertaModel.from_pretrained('roberta-large')    #use roberta-large or roberta-base\n","        self.model_TFIDF               = snnmodel                                        #Pre-trained SNN trained with TF-IDF features\n","\n","        self.drop                      = nn.Dropout(p = 0.3)\n","\n","        self.output                    = nn.Linear(self.robertaModel.config.hidden_size, n_classes)\n","\n","        self.input_size_tfidf_only     = self.robertaModel.config.hidden_size + len(tfidf.get_feature_names())\n","        self.input_size_tfidf_pca      = self.robertaModel.config.hidden_size + HIDDEN_UNITS\n","\n","        self.dense                     = nn.Linear( self.input_size_tfidf_only,  self.input_size_tfidf_only)\n","        self.out_proj                  = nn.Linear( self.input_size_tfidf_only, n_classes)\n","        self.out_pca                   = nn.Linear( self.input_size_tfidf_pca, n_classes)\n","\n","        self.input_size_preTrain_tfidf = self.robertaModel.config.hidden_size +  HIDDEN_UNITS \n","        self.out                       = nn.Linear(self.input_size_preTrain_tfidf, n_classes)\n","\n","        self.softmax                   = nn.Softmax(dim = 1)\n","\n","    def forward(self, input_ids, attention_mask, inputs_tfidf_feats, pca_transformed_feats, modelType):\n","        roberta_output     = self.robertaModel(\n","            input_ids      = input_ids,               #Input sequence tokens\n","            attention_mask = attention_mask )         #Mask to avoid performing attention on padding tokens\n","    #print(roberta_output[1].shape)\n","        if modelType   == 'roberta-only':\n","            pooled_output = roberta_output[1]           #Using pooled output\n","            output        = self.drop(pooled_output)\n","            output        = self.output(output)\n","\n","        elif modelType == 'roberta-tfIdf':\n","            soutput = roberta_output[1]#---------        experimenting with pooled output \n","            #soutput = roberta_output[0][:, 0, :]        #taking <s> token (equivalent to [CLS] token in BERT)\n","            x       = torch.cat((soutput, inputs_tfidf_feats) , dim=1)\n","            x       = self.drop(x)\n","            output  = self.out_proj(x)\n","\n","        elif modelType == 'roberta-pcaTfidf':\n","            soutput = roberta_output[1]\n","            x       = torch.cat((soutput, pca_transformed_feats) , dim=1)\n","            x       = self.drop(x)\n","            output  = self.out_pca(x)\n","\n","        elif modelType == 'roberta-TrainedTfIdf':\n","            tfidf_hidddenLayer, tfidf_output = self.model_TFIDF(inputs_tfidf_feats)\n","            #print(tfidf_hidddenLayer.shape)\n","            #print(tfidf_output.shape)\n","\n","          #Conactenating pooled output from RoBERTa with the hidden layer from the pre-trained SNN using TF-IDF features. \n","          #pooled_output = torch.cat((roberta_output[1], tfidf_output) , dim=1)-------- Experimenting with Output of pre-trained SNN \n","            pooled_output = torch.cat((roberta_output[1], tfidf_hidddenLayer) , dim=1)\n","            output        = self.drop(pooled_output)\n","            output        = self.out(output)\n","\n","        return self.softmax(output)\n"],"metadata":{"id":"vgVR4xDQx3lo","executionInfo":{"status":"ok","timestamp":1643477686769,"user_tz":-60,"elapsed":2,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["#Instantiating a BiasClassifier object as our model and loading the model onto the GPU.\n","model = BiasClassifier(len(CLASS_NAMES))\n","model = model.to(device)\n","#print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VpA9_pzMx3jP","executionInfo":{"status":"ok","timestamp":1643477699606,"user_tz":-60,"elapsed":9295,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}},"outputId":"f18b42b8-be18-4f67-a0d1-56786e2b5956"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]}]},{"cell_type":"code","source":["# print(model)"],"metadata":{"id":"9a3Nle4hm7xE","executionInfo":{"status":"ok","timestamp":1643475547596,"user_tz":-60,"elapsed":3,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["'''Using the same optimiser as used in BERT paper\n","with a different learning rate'''\n","optimizer = AdamW(model.parameters(), \n","                  lr = 2e-6, \n","                  # lr = 1e-5,\n","                  correct_bias= False)\n","\n","totalSteps = len(trainDataLoader) * EPOCHS\n","\n","scheduler = get_linear_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=0,\n","            num_training_steps = totalSteps\n",")\n","\n","'''Using class-weights to accomodate heavily imbalanced data. \n","These weights were learnt by running several experiments using \n","other weights and the weights that produced the best results have\n","finally been used here'''\n","\n","weights      = [0.8, 1.2]\n","# weights = class_weights\n","class_weights = torch.FloatTensor(weights)\n","\n","# class_weights = class_weight.compute_class_weight(\n","#                                         class_weight = \"balanced\",\n","#                                         classes = np.unique(y_train),\n","#                                         y = y_train                                                    \n","#                                     )\n","print(class_weights)\n","\n","\n","lossFunction = nn.CrossEntropyLoss(weight = class_weights).to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3rDYXr66x3gw","executionInfo":{"status":"ok","timestamp":1643477699606,"user_tz":-60,"elapsed":4,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}},"outputId":"8cdf7de8-445a-44df-b570-512de79c4789"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.8000, 1.2000])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["#This function is used for training the model with 'roberta-TrainedTfIdf'. \n","def train_epoch(\n","  model,\n","  dataLoader,\n","  lossFunction,\n","  optimizer,\n","  device,\n","  scheduler,\n","  n_examples\n","):\n","    model = model.train()\n","    losses = []\n","    correctPredictions = 0\n","\n","    for d in dataLoader:\n","    \n","        input_ids              = d[\"input_ids\"].to(device)                           #Loading input ids to GPU\n","        attention_mask         = d[\"attention_mask\"].to(device)                      #Loading attention mask to GPU\n","        labels            = d[\"labels\"].to(device)                          #Loading label value to GPU\n","        sentences            = d[\"sentences\"]\n","        # Features               = d[\"Features\"]                                  \n","        tfidf_transform        = x_train_feats.transform(sentences)\n","        tfidf_transform_tensor = torch.tensor(scipy.sparse.csr_matrix.todense(tfidf_transform)).float()   \n","        pca_tensor             = p.transform(tfidf_transform_tensor)\n","\n","        pca_tensor = torch.from_numpy(pca_tensor).float()\n","        pca_tensor = pca_tensor.to(device)\n","        tfidf_transform_tensor = tfidf_transform_tensor.to(device)\n","\n","        #Getting the output from our model (Object of StanceClassification class) for train data\n","        outputs = model(\n","          input_ids             = input_ids,\n","          attention_mask        = attention_mask,\n","          inputs_tfidf_feats    = tfidf_transform_tensor,\n","          pca_transformed_feats = pca_tensor,\n","          modelType             = 'roberta-TrainedTfIdf'\n","        )\n","\n","        #Determining the model predictions\n","        _, predictionIndices = torch.max(outputs, dim=1)\n","        loss = lossFunction(outputs, labels)\n","\n","        #Calculating the correct predictions for accuracy\n","        correctPredictions += torch.sum(predictionIndices == labels)\n","        losses.append(loss.item())\n","        loss.backward()\n","        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","\n","    return np.mean(losses), correctPredictions.double() / n_examples"],"metadata":{"id":"poIPud3Dx3eJ","executionInfo":{"status":"ok","timestamp":1643477699606,"user_tz":-60,"elapsed":3,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["#This function is used for evaluating the model on the development and test set\n","def eval_model(\n","    model, \n","    dataLoader, \n","    lossFunction,\n","    device,\n","    n_examples\n","    ):\n","    model = model.eval()\n","    losses = []\n","    correctPredictions = 0\n","\n","    with torch.no_grad():\n","        for d in dataLoader:\n","            input_ids              = d[\"input_ids\"].to(device)                          #Loading input ids to GPU\n","            attention_mask         = d[\"attention_mask\"].to(device)                     #Loading attention mask to GPU\n","            labels            = d[\"labels\"].to(device)                         #Loading label values to GPU\n","            sentences            = d[\"sentences\"]\n","            tfidf_transform        = x_train_feats.transform(sentences)\n","            tfidf_transform_tensor = torch.tensor(scipy.sparse.csr_matrix.todense(tfidf_transform)).float()    \n","\n","            pca_tensor             = p.transform(tfidf_transform_tensor)\n","\n","            pca_tensor = torch.from_numpy(pca_tensor).float()\n","            pca_tensor = pca_tensor.to(device)\n","            tfidf_transform_tensor = tfidf_transform_tensor.to(device)\n","\n","            #Getting the softmax output from model for dev data\n","            outputs = model(\n","            input_ids             = input_ids,\n","            attention_mask        = attention_mask,\n","            inputs_tfidf_feats    = tfidf_transform_tensor,\n","            pca_transformed_feats = pca_tensor,\n","            modelType             = 'roberta-pcaTfidf'\n","            )\n","\n","            #Determining the model predictions\n","            _, predictionIndices = torch.max(outputs, dim=1)\n","            loss = lossFunction(outputs, labels)\n","\n","            #Calculating the correct predictions for accuracy\n","            correctPredictions += torch.sum(predictionIndices == labels)\n","            losses.append(loss.item())\n","\n","    return np.mean(losses), correctPredictions.double() / n_examples\n"],"metadata":{"id":"eJIixjnGx3bm","executionInfo":{"status":"ok","timestamp":1643477701291,"user_tz":-60,"elapsed":1,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["#fine tuning ROBERTa and validating it \n","\n","for epoch in range(EPOCHS):\n","    print(f'Epoch {epoch + 1}')\n","    trainLoss, trainAccuracy = train_epoch(\n","        model,\n","        trainDataLoader,\n","        lossFunction,\n","        optimizer,\n","        device,\n","        scheduler,\n","        len(train_df)\n","      )\n","    print(f'Training loss {trainLoss} Training accuracy {trainAccuracy}')\n","    devLoss, devAccuracy = eval_model(\n","        model,\n","        developmentDataLoader,\n","        lossFunction,\n","        device,\n","        len(dev_df)\n","      )\n","    print(f'Development loss {devLoss} Development accuracy {devAccuracy}')\n","    # from google.colab import drive\n","    # drive.mount('/content/gdrive')\n","    \n","    # model_save_name = f'Roberta_tfidf_{epoch}.pt'\n","    # path = F\"/content/gdrive/My Drive/{model_save_name}\" \n","    # torch.save(model.state_dict(), path)\n","    print()\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":550},"id":"ALoSeA1qx3ZL","executionInfo":{"status":"error","timestamp":1643478039270,"user_tz":-60,"elapsed":335361,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}},"outputId":"97c838a8-c903-43c7-c1b6-86d0ca74cdbf"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["Training loss 0.6942259353304666 Training accuracy 0.5065632458233891\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-a0efd221f84f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlossFunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m       )\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Development loss {devLoss} Development accuracy {devAccuracy}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-b51a0d850620>\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(model, dataLoader, lossFunction, device, n_examples)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m#Calculating the correct predictions for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mcorrectPredictions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictionIndices\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrectPredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["#This function gets the predictions from the model after it is trained.\n","def get_predictions(model, data_loader):\n","\n","    model = model.eval()\n","    review_texta = []\n","#     review_textb = []               #     !! Change - commented\n","    predictions = []\n","    prediction_probs = []\n","    real_values = []\n","\n","    with torch.no_grad():\n","        for d in data_loader:\n","\n","            sentences                 = d[\"sentences\"]\n","#             textbs                 = d[\"secondSeq\"]\n","            input_ids              = d[\"input_ids\"].to(device)\n","            attention_mask         = d[\"attention_mask\"].to(device)\n","            labels                 = d[\"labels\"].to(device)\n","            # Features            = d[\"Features\"]\n","            tfidf_transform        = tfidf.transform(sentences)\n","            tfidf_transform_tensor = torch.tensor(scipy.sparse.csr_matrix.todense(tfidf_transform)).float()\n","\n","            pca_tensor             =  p.transform(tfidf_transform_tensor)\n","\n","            pca_tensor = torch.from_numpy(pca_tensor).float()\n","            pca_tensor = pca_tensor.to(device)\n","            tfidf_transform_tensor = tfidf_transform_tensor.to(device)\n","\n","            #Getting the softmax output from model\n","            outputs = model(\n","                input_ids             = input_ids,\n","                attention_mask        = attention_mask,\n","                inputs_tfidf_feats    = tfidf_transform_tensor,\n","                pca_transformed_feats = pca_tensor,\n","                modelType             = 'roberta-TrainedTfIdf'\n","                )\n","            _, preds = torch.max(outputs, dim=1)     #Determining the model predictions\n","\n","            review_texta.extend(sentences)\n","#             review_textb.extend(textbs)\n","            predictions.extend(preds)\n","            prediction_probs.extend(outputs)\n","            real_values.extend(labels)\n","    predictions = torch.stack(predictions).cpu()\n","    prediction_probs = torch.stack(prediction_probs).cpu()\n","    real_values = torch.stack(real_values).cpu()\n","  \n","    return review_texta, predictions, prediction_probs, real_values\n","#    return review_texta, review_textb, predictions, prediction_probs, real_values"],"metadata":{"id":"MRh04FOHx3Wq","executionInfo":{"status":"ok","timestamp":1643478044469,"user_tz":-60,"elapsed":299,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["#Getting model predictions on dev dataset\n","# firstSeq_dev, secondSeq_dev, yHat_dev, predProbs_dev, yTest_dev = get_predictions(\n","#   model,\n","#   developmentDataLoader\n","# )\n","\n","firstSeq_dev, yHat_dev, predProbs_dev, yTest_dev = get_predictions(\n","  model,\n","  developmentDataLoader\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wK8tjWBfx3UD","executionInfo":{"status":"ok","timestamp":1643477634918,"user_tz":-60,"elapsed":23219,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}},"outputId":"2f051cc9-fc71-4d8f-fe2c-09641ac0c2bc"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":[" #Printing classification report for dev dataset (Evaluating the model on Dev set)\n","print(classification_report(yTest_dev, yHat_dev, target_names= CLASS_NAMES))\n","print(confusion_matrix(yTest_dev, yHat_dev))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9AglBHOFx3Rj","executionInfo":{"status":"ok","timestamp":1643477634918,"user_tz":-60,"elapsed":3,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}},"outputId":"f80df287-b7c2-4598-cc4a-b0d735b93e11"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.83      0.02      0.03       635\n","           1       0.41      1.00      0.58       431\n","\n","    accuracy                           0.41      1066\n","   macro avg       0.62      0.51      0.30      1066\n","weighted avg       0.66      0.41      0.25      1066\n","\n","[[ 10 625]\n"," [  2 429]]\n"]}]},{"cell_type":"code","source":["# model_save_name = 'RoBERTaLarge_TFIDFV2P_cmv_step2.pt'\n","# path = F\"/content/gdrive/My Drive/Colab Notebooks/{model_save_name}\" \n","# torch.save(model.state_dict(), path)"],"metadata":{"id":"FPuREv5Mx3O1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Getting model predictions on test dataset\n","firstSeq_test, yHat_test, predProbs_test, yTest_test = get_predictions(\n","  model,\n","  testDataLoader\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6VUzBxx0lRaN","executionInfo":{"status":"ok","timestamp":1643475436000,"user_tz":-60,"elapsed":50121,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}},"outputId":"9cf91097-b501-4e19-8a25-6c5919c90691"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["#Printing classification report for test dataset (Evaluating the model on test set)\n","print(classification_report(yTest_test, yHat_test, target_names= CLASS_NAMES))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qnALUvqFlRXr","executionInfo":{"status":"ok","timestamp":1643475455292,"user_tz":-60,"elapsed":287,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}},"outputId":"535d8a1d-f579-4e11-91dc-a438665c300b"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.59      0.98      0.74      1252\n","           1       0.35      0.02      0.03       852\n","\n","    accuracy                           0.59      2104\n","   macro avg       0.47      0.50      0.39      2104\n","weighted avg       0.50      0.59      0.45      2104\n","\n"]}]},{"cell_type":"code","source":["print(confusion_matrix(yTest_test, yHat_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SVcbHADQlRVN","executionInfo":{"status":"ok","timestamp":1643475460854,"user_tz":-60,"elapsed":264,"user":{"displayName":"Garima Mudgal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GihbN2FEuxMGO0JqJ3fdQhmaS3HMx15Ipgmo6tbPQ=s64","userId":"14901317976461361357"}},"outputId":"ffafe7e0-6ed4-4266-9df1-c46a9238cc7a"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1226   26]\n"," [ 838   14]]\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"8zaj9twmlRSn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"ex-kwfBilRQH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"V1bHn0whlRNT"},"execution_count":null,"outputs":[]}]}